import google.generativeai as genai
import seaborn as sns
import matplotlib.pyplot as plt
from langgraph.graph import StateGraph, END
from typing import TypedDict
# ======================
# Gemini API config
# ======================
#genai.configure(api_key="AIzaSyCzsavhQ8vVRIiGMlZJiN8872SOMWHc6cY")
genai.configure(api_key="AIzaSyCzsavhQ8vVRIiGMlZJiN8872SOMWHc6cY")
model = genai.GenerativeModel("models/gemini-2.5-flash")
import regex as re
import json, requests  # ‚ö†Ô∏è b·ªè ch·ªØ "re" ·ªü ƒë√¢y

# =========================
# agent 1
# =========================

# g·ªçi model ƒë·ªÉ quy·∫øt ƒë·ªãnh route ‚Äî ri√™ng cho routing (kh√¥ng tr·ªôn v·ªõi agent4/5)
def ask_router(prompt: str) -> str:
    guard_prefix = """
‚ö†Ô∏è QUY T·∫ÆC B·∫ÆT BU·ªòC:
Ch·ªâ tr·∫£ v·ªÅ m·ªôt trong c√°c gi√° tr·ªã ch√≠nh x√°c (kh√¥ng th√™m g√¨ kh√°c):
- agent4
- agent4,agent5
- none
---
"""
    try:
        full = guard_prefix.strip() + "\n\n" + prompt.strip()
        resp = model.generate_content(full)
        text = resp.text.strip().lower()
        # l√†m s·∫°ch: ch·ªâ gi·ªØ ch·ªØ th∆∞·ªùng, s·ªë, d·∫•u ph·∫©y
        text = re.sub(r"[^a-z0-9,]", "", text)
        if text in ("agent4","agent4agent5","agent4,agent5"):
            # chu·∫©n h√≥a "agent4agent5" -> "agent4,agent5"
            return "agent4,agent5" if "agent5" in text and "agent4" in text else text
        return "none"
    except Exception as e:
        print("‚ùå ask_router error:", e)
        return "none"

prompt1 = """
B·∫°n l√† Tr∆∞·ªüng nh√≥m ƒëi·ªÅu ph·ªëi. Ng∆∞·ªùi d√πng h·ªèi: "{user_input}"
N·∫øu h·ªç mu·ªën n·ªôi dung/t√≥m t·∫Øt -> tr·∫£ v·ªÅ "agent4,agent5".
N·∫øu h·ªç ch·ªâ mu·ªën metadata (t√°c gi·∫£, nƒÉm, th·ªÉ lo·∫°i, ·∫£nh, wiki) -> tr·∫£ v·ªÅ "agent4".
N·∫øu ngo√†i ph·∫°m vi s√°ch -> tr·∫£ v·ªÅ "none".
Ch·ªâ tr·∫£ m·ªôt trong 3 gi√° tr·ªã, kh√¥ng gi·∫£i th√≠ch th√™m.
"""
# =========================
# agent4
# =========================
BOOK_EXTRACTION_PROMPT = """
B·∫°n l√† m·ªôt tr·ª£ l√Ω ƒë·ªçc hi·ªÉu s√°ch th√¥ng minh.
Ng∆∞·ªùi d√πng h·ªèi: "{user_question}"

Trong danh s√°ch s√°ch d∆∞·ªõi ƒë√¢y:
{books_json}

Nhi·ªám v·ª•:
1. Ph√¢n t√≠ch xem ng∆∞·ªùi d√πng ƒëang mu·ªën:
   - M·ªôt **quy·ªÉn s√°ch c·ª• th·ªÉ** (v√≠ d·ª•: "S·ªë ƒë·ªè", "cu·ªën Ki√™u h√£nh v√† ƒë·ªãnh ki·∫øn") 
     ‚Üí ch·ªâ tr·∫£ v·ªÅ 1 s√°ch g·∫ßn ƒë√∫ng nh·∫•t.
   - Hay mu·ªën **nhi·ªÅu s√°ch c√πng ch·ªß ƒë·ªÅ** (v√≠ d·ª•: "5 quy·ªÉn", "m·ªôt s·ªë s√°ch v·ªÅ l·ªãch s·ª≠/l√£ng m·∫°n") 
     ‚Üí tr·∫£ v·ªÅ t·ªëi ƒëa 5 s√°ch ph√π h·ª£p nh·∫•t.

2. Tr·∫£ v·ªÅ **duy nh·∫•t m·ªôt JSON h·ª£p l·ªá**:
   - N·∫øu 1 quy·ªÉn ‚Üí m·ªôt object.
   - N·∫øu nhi·ªÅu quy·ªÉn ‚Üí m·ªôt m·∫£ng JSON g·ªìm t·ªëi ƒëa 5 object.

M·ªói ƒë·ªëi t∆∞·ª£ng s√°ch c√≥ c·∫•u tr√∫c sau:
{{
  "book_name": "<t√™n s√°ch>",
  "author": "<t√°c gi·∫£ n·∫øu c√≥>",
  "genre": "<th·ªÉ lo·∫°i n·∫øu c√≥>",
  "year": "<nƒÉm n·∫øu c√≥>",
  "country": "<qu·ªëc gia n·∫øu c√≥>",
  "title_y": "<t√™n ph·ª• n·∫øu c√≥>",
  "wiki_link": "<link Wikipedia n·∫øu c√≥>",
  "image_link": "<link h√¨nh ·∫£nh n·∫øu c√≥>"
}}

‚ö†Ô∏è Ch·ªâ xu·∫•t ra JSON, kh√¥ng th√™m gi·∫£i th√≠ch ho·∫∑c markdown.
N·∫øu kh√¥ng c√≥ s√°ch ph√π h·ª£p, tr·∫£ v·ªÅ [].
"""



def ask_agent4(user_question: str, books_list: list) -> str:
    """
    Sinh JSON danh s√°ch s√°ch ph√π h·ª£p nh·∫•t t·ª´ c√¢u h·ªèi v√† danh s√°ch s√°ch.
    ‚ö†Ô∏è KH√îNG thay ƒë·ªïi format ƒë·∫ßu ra. Tr·∫£ v·ªÅ chu·ªói text raw c·ªßa Gemini.
    """
    prompt = BOOK_EXTRACTION_PROMPT.format(
        user_question=user_question,
        books_json=json.dumps(books_list, ensure_ascii=False)
    )

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"‚ùå L·ªói khi g·ªçi model: {e}"

# =========================
# agent5
# =========================

embedding_model_name = "models/text-embedding-004"
fixed_vector_size = 1024

# Model suy lu·∫≠n

AGENT5_PROMPT_TEMPLATE = """
B·∫°n l√† m·ªôt tr·ª£ l√Ω ƒë·ªçc hi·ªÉu s√°ch. D·ª±a tr√™n c√°c ƒëo·∫°n sau:

{context}

H√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch **r√µ r√†ng, ng·∫Øn g·ªçn, di·ªÖn gi·∫£i b·∫±ng l·ªùi c·ªßa b·∫°n**, kh√¥ng copy nguy√™n vƒÉn:
C√¢u h·ªèi: {query}
"""

# ===========================================
# üîπ H√ÄM G·ªåI GEMINI (gi·ªØ nguy√™n output)
# ===========================================
def ask_agent5(prompt: str):
    """G·ªçi model Gemini 2.5 Flash ƒë·ªÉ sinh n·ªôi dung (tr·∫£ raw text)."""
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"‚ùå L·ªói khi g·ªçi model: {e}"

# ===========================================
# üîπ H√ÄM T·∫†O EMBEDDING (gi·ªØ nguy√™n logic pad/cut + norm)
# ===========================================
def get_gemini_embedding(texts):
    """Sinh embedding t·ª´ Gemini, c·∫Øt/pad v·ªÅ fixed_vector_size = 1024, chu·∫©n h√≥a."""
    if isinstance(texts, str):
        texts = [texts]
    embeddings = []
    for i in range(0, len(texts), 50):
        batch = texts[i:i+50]
        try:
            res = genai.embed_content(model=embedding_model_name, content=batch)
            for emb in res["embedding"]:
                if len(emb) > fixed_vector_size:
                    emb = emb[:fixed_vector_size]
                elif len(emb) < fixed_vector_size:
                    emb += [0.0] * (fixed_vector_size - len(emb))
                emb = np.array(emb, dtype=np.float32)
                norm = np.linalg.norm(emb)
                if norm > 0:
                    emb /= norm
                embeddings.append(emb.tolist())
        except Exception:
            embeddings.extend([[0.0] * fixed_vector_size] * len(batch))
    return embeddings
